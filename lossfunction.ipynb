{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from table_LLM import *\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/hyun/paper/dataset/train_data_1000.csv')\n",
    "data_x = data.iloc[:, :-1]\n",
    "data_y = data.iloc[:, -1:]\n",
    "x_columns = data_x.columns\n",
    "y_column = data_y.columns\n",
    "\n",
    "data[\"result\"] = data[\"result\"].apply(lambda x: f\"<num>{str(x)}<num>\")\n",
    "\n",
    "unique_words = table_util.get_unique_word(data, x_columns=x_columns, y_column=y_column)\n",
    "special_word = [\"is\", \",\", \" \", \"<end>\", \"<start>\", \"<pad>\"]\n",
    "unique_words.extend(special_word)\n",
    "unique_words = natsorted(unique_words)\n",
    "\n",
    "\n",
    "unique_words.append(\"<num>\")\n",
    "unique_words.extend([\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word2idx = {word: idx for idx, word in enumerate(unique_words)}\n",
    "idx2unique_word = {idx: word for idx, word in enumerate(unique_words)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " ',': 1,\n",
       " '<end>': 2,\n",
       " '<pad>': 3,\n",
       " '<start>': 4,\n",
       " 'Facility1_1': 5,\n",
       " 'Facility1_2': 6,\n",
       " 'Facility1_3': 7,\n",
       " 'Facility1_4': 8,\n",
       " 'Facility1_5': 9,\n",
       " 'Facility1_6': 10,\n",
       " 'Facility1_7': 11,\n",
       " 'Facility2_1': 12,\n",
       " 'Facility2_2': 13,\n",
       " 'Facility2_3': 14,\n",
       " 'Facility2_4': 15,\n",
       " 'Facility2_5': 16,\n",
       " 'Facility2_6': 17,\n",
       " 'Facility2_7': 18,\n",
       " 'Facility2_8': 19,\n",
       " 'Facility3_1': 20,\n",
       " 'Facility3_2': 21,\n",
       " 'Facility3_3': 22,\n",
       " 'Facility3_4': 23,\n",
       " 'Facility3_5': 24,\n",
       " 'Facility3_6': 25,\n",
       " 'Facility4_1': 26,\n",
       " 'Facility4_2': 27,\n",
       " 'Facility4_3': 28,\n",
       " 'Facility4_4': 29,\n",
       " 'Facility4_5': 30,\n",
       " 'Facility4_6': 31,\n",
       " 'Facility4_7': 32,\n",
       " 'Facility5_1': 33,\n",
       " 'Facility5_2': 34,\n",
       " 'Facility5_3': 35,\n",
       " 'Facility5_4': 36,\n",
       " 'Facility5_5': 37,\n",
       " 'Facility5_6': 38,\n",
       " 'Facility5_7': 39,\n",
       " 'Facility5_8': 40,\n",
       " 'Facility6_1': 41,\n",
       " 'Facility6_2': 42,\n",
       " 'Facility6_3': 43,\n",
       " 'Facility6_4': 44,\n",
       " 'Facility6_5': 45,\n",
       " 'is': 46,\n",
       " 'process1': 47,\n",
       " 'process2': 48,\n",
       " 'process3': 49,\n",
       " 'process4': 50,\n",
       " 'process5': 51,\n",
       " 'process6': 52,\n",
       " 'result': 53,\n",
       " '<num>': 54,\n",
       " '0': 55,\n",
       " '1': 56,\n",
       " '2': 57,\n",
       " '3': 58,\n",
       " '4': 59,\n",
       " '5': 60,\n",
       " '6': 61,\n",
       " '7': 62,\n",
       " '8': 63,\n",
       " '9': 64,\n",
       " '.': 65}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoStepTokenizer():\n",
    "    def __init__(self, unique_word2idx, idx2unique_word):\n",
    "        self.unique_word2idx = unique_word2idx\n",
    "        self.idx2unique_word = idx2unique_word\n",
    "        self.vocab_size = len(unique_word2idx)\n",
    "        self.eos_token = \"<end>\"\n",
    "        self.sos_token = \"<start>\"\n",
    "        self.pad_token = \"<pad>\"\n",
    "        self.pad_token_idx = self.unique_word2idx[self.pad_token]\n",
    "        self.num_token = \"<num>\"\n",
    "        self.num_token_idx = self.unique_word2idx[self.num_token]\n",
    "\n",
    "    def _encode(self, sentence):\n",
    "        token_list = []\n",
    "        position_list = []\n",
    "        token_type_list = []\n",
    "        temp = \"\"\n",
    "        position = 0\n",
    "        flag = False\n",
    "        for word in sentence:\n",
    "            temp += word\n",
    "            if temp in self.unique_word2idx:\n",
    "\n",
    "                token_list.append(self.unique_word2idx[temp]) # token\n",
    "                position_list.append(position) # position\n",
    "\n",
    "                if self.unique_word2idx[temp] > self.num_token_idx:\n",
    "                    token_type_list.append(1)\n",
    "                else:\n",
    "                    token_type_list.append(0)\n",
    "\n",
    "\n",
    "\n",
    "                position += 1\n",
    "                temp = \"\"\n",
    "        return token_list, position_list, token_type_list\n",
    "    \n",
    "    def _decode(self, tokens):\n",
    "        sentence = [self.idx2unique_word[token] for token in tokens]\n",
    "        sentence = \"\".join(sentence)\n",
    "        return sentence\n",
    "    \n",
    "    def encode(self, sentence):\n",
    "        if isinstance(sentence, str):\n",
    "            return self._encode(sentence)\n",
    "        elif isinstance(sentence, list):\n",
    "            return [self._encode(s) for s in sentence]\n",
    "        \n",
    "    def decode(self, tokens):\n",
    "        if isinstance(tokens[0], list):\n",
    "            return [self._decode(t) for t in tokens]\n",
    "        else:\n",
    "            return self._decode(tokens)\n",
    "        \n",
    "    def __call__(self, sentence):\n",
    "        return self.encode(sentence)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TwoStepTokenizer(unique_word2idx, idx2unique_word)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TableDataset_v2.from_pandas(data, preserve_index=False)\n",
    "dataset.set_tokenizer(tokenizer)\n",
    "dataset.set_length(max_length=55)\n",
    "dataset.set_generate_mode(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 0, 46, 0, 28, 1, 0, 52, 0, 46, 0, 45, 1, 0, 51, 0, 46, 0, 35, 1, 0, 47, 0, 46, 0, 6, 1, 0, 53, 0, 46, 0, 54, 59, 61, 65, 56, 58, 54, 1, 0, 49, 0, 46, 0, 24, 2]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'process4 is Facility4_3, process3 is Facility3_5, process1 is Facility1_2, process2 is Facility2_5, process5 is Facility5_3, result is <num>46.13<num>, process6 is Facility6_5<end>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode(\"process4 is Facility4_3, process6 is Facility6_5, process5 is Facility5_3, process1 is Facility1_2, result is <num>46.13<num>, process3 is Facility3_5<end>\")\n",
    "print(encoded_tokens[0])\n",
    "print(encoded_tokens[1])\n",
    "print(encoded_tokens[2])\n",
    "tokenizer.decode([50, 0, 46, 0, 28, 1, 0, 49, 0, 46, 0, 24, 1, 0, 47, 0, 46, 0, 6, 1, 0, 48, 0, 46, 0, 16, 1, 0, 51, 0, 46, 0, 35, 1, 0, 53, 0, 46, 0, 54, 59, 61, 65, 56, 58, 54, 1, 0, 52, 0, 46, 0, 45, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embed_size = 128\n",
    "num_heads = 8\n",
    "hidden_size = 256\n",
    "num_layers = 4\n",
    "max_seq_length = 55\n",
    "batch_size = 32\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import Conv1d as Conv1D\n",
    "from torch.nn import GELU as gelu\n",
    "from torch.nn import LayerNorm as LayerNorm\n",
    "\n",
    "# def gelu(x):\n",
    "#     return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "# class LayerNorm(nn.Module):\n",
    "#     \"\"\"\n",
    "#     레이어의 출력에 대해 평균과 분산을 구하고 이를 통해 출력을 정규화하는 레이어\n",
    "\n",
    "#     \"\"\"\n",
    "#     def __init__(self, hidden_size, eps=1e-12):\n",
    "#         \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "#         \"\"\"\n",
    "#         super(LayerNorm, self).__init__()\n",
    "#         self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "#         self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "#         self.variance_epsilon = eps\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         u = x.mean(-1, keepdim=True)\n",
    "#         s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "#         x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "#         return self.weight * x + self.bias\n",
    "\n",
    "# class Conv1D(nn.Module):\n",
    "#     \"\"\"\n",
    "#     1D Convolution 레이어.  == torch.nn.Conv1d\n",
    "#     \"\"\"\n",
    "#     def __init__(self, nf, nx):\n",
    "#         super(Conv1D, self).__init__()\n",
    "#         self.nf = nf\n",
    "#         w = torch.empty(nx, nf)\n",
    "#         nn.init.normal_(w, std=0.02)\n",
    "#         self.weight = Parameter(w)\n",
    "#         self.bias = Parameter(torch.zeros(nf))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         size_out = x.size()[:-1] + (self.nf,)\n",
    "#         x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
    "#         x = x.view(*size_out)\n",
    "#         return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, nx, n_ctx, config, scale=False):\n",
    "        super(Attention, self).__init__()\n",
    "        n_state = nx  # in Attention: n_state=768 (nx=n_embd)\n",
    "        # [switch nx => n_state from Block to Attention to keep identical to TF implem]\n",
    "        assert n_state % config.n_head == 0\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
    "        self.n_head = config.n_head\n",
    "        self.split_size = n_state\n",
    "        self.scale = scale\n",
    "        self.c_attn = Conv1D(n_state * 3, nx)\n",
    "        self.c_proj = Conv1D(n_state, nx)\n",
    "\n",
    "    def _attn(self, q, k, v):\n",
    "        w = torch.matmul(q, k)\n",
    "        if self.scale:\n",
    "            w = w / math.sqrt(v.size(-1))\n",
    "        nd, ns = w.size(-2), w.size(-1)\n",
    "        b = self.bias[:, :, ns-nd:ns, :ns]\n",
    "        w = w * b - 1e10 * (1 - b)\n",
    "        w = nn.Softmax(dim=-1)(w)\n",
    "        return torch.matmul(w, v)\n",
    "\n",
    "    def merge_heads(self, x):\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
    "        return x.view(*new_x_shape)  # in Tensorflow implem: fct merge_states\n",
    "\n",
    "    def split_heads(self, x, k=False):\n",
    "        new_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
    "        x = x.view(*new_x_shape)  # in Tensorflow implem: fct split_states\n",
    "        if k:\n",
    "            return x.permute(0, 2, 3, 1)  # (batch, head, head_features, seq_length)\n",
    "        else:\n",
    "            return x.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
    "\n",
    "    def forward(self, x, layer_past=None):\n",
    "        x = self.c_attn(x)\n",
    "        query, key, value = x.split(self.split_size, dim=2)\n",
    "        query = self.split_heads(query)\n",
    "        key = self.split_heads(key, k=True)\n",
    "        value = self.split_heads(value)\n",
    "        if layer_past is not None:\n",
    "            past_key, past_value = layer_past[0].transpose(-2, -1), layer_past[1]  # transpose back cf below\n",
    "            key = torch.cat((past_key, key), dim=-1)\n",
    "            value = torch.cat((past_value, value), dim=-2)\n",
    "        present = torch.stack((key.transpose(-2, -1), value))  # transpose to have same shapes for stacking\n",
    "        a = self._attn(query, key, value)\n",
    "        a = self.merge_heads(a)\n",
    "        a = self.c_proj(a)\n",
    "        return a, present\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_state, config):  # in MLP: n_state=3072 (4 * n_embd)\n",
    "        super(MLP, self).__init__()\n",
    "        nx = config.n_embd\n",
    "        self.c_fc = Conv1D(n_state, nx)\n",
    "        self.c_proj = Conv1D(nx, n_state)\n",
    "        self.act = gelu\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.c_fc(x))\n",
    "        h2 = self.c_proj(h)\n",
    "        return h2\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_ctx, config, scale=False):\n",
    "        super(Block, self).__init__()\n",
    "        nx = config.n_embd\n",
    "        self.ln_1 = LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
    "        self.attn = Attention(nx, n_ctx, config, scale)\n",
    "        self.ln_2 = LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
    "        self.mlp = MLP(4 * nx, config)\n",
    "\n",
    "    def forward(self, x, layer_past=None):\n",
    "        a, present = self.attn(self.ln_1(x), layer_past=layer_past)\n",
    "        x = x + a\n",
    "        m = self.mlp(self.ln_2(x))\n",
    "        x = x + m\n",
    "        return x, present\n",
    "\n",
    "class GPT2Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(GPT2Model, self).__init__()\n",
    "        self.n_layer = config.n_layer\n",
    "        self.n_embd = config.n_embd\n",
    "        self.n_vocab = config.vocab_size\n",
    "\n",
    "        self.wte = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        self.wpe = nn.Embedding(config.n_positions, config.n_embd)\n",
    "        block = Block(config.n_ctx, config, scale=True)\n",
    "        self.h = nn.ModuleList([copy.deepcopy(block) for _ in range(config.n_layer)])\n",
    "        self.ln_f = LayerNorm(config.n_embd, eps=config.layer_norm_epsilon)\n",
    "\n",
    "    def set_embeddings_weights(self, model_embeddings_weights):\n",
    "        embed_shape = model_embeddings_weights.shape\n",
    "        self.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\n",
    "        self.decoder.weight = model_embeddings_weights  # Tied weights\n",
    "\n",
    "    def forward(self, input_ids, position_ids=None, token_type_ids=None, past=None):\n",
    "        if past is None:\n",
    "            past_length = 0\n",
    "            past = [None] * len(self.h)\n",
    "        else:\n",
    "            past_length = past[0][0].size(-2)\n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(past_length, input_ids.size(-1) + past_length, dtype=torch.long,\n",
    "                                        device=input_ids.device)\n",
    "            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "\n",
    "        input_shape = input_ids.size()\n",
    "        input_ids = input_ids.view(-1, input_ids.size(-1))\n",
    "        position_ids = position_ids.view(-1, position_ids.size(-1))\n",
    "\n",
    "        inputs_embeds = self.wte(input_ids)\n",
    "        position_embeds = self.wpe(position_ids)\n",
    "        if token_type_ids is not None:\n",
    "            token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1))\n",
    "            token_type_embeds = self.wte(token_type_ids)\n",
    "        else:\n",
    "            token_type_embeds = 0\n",
    "        hidden_states = inputs_embeds + position_embeds + token_type_embeds\n",
    "        presents = []\n",
    "        for block, layer_past in zip(self.h, past):\n",
    "            hidden_states, present = block(hidden_states, layer_past)\n",
    "            presents.append(present)\n",
    "        hidden_states = self.ln_f(hidden_states)\n",
    "        output_shape = input_shape + (hidden_states.size(-1),)\n",
    "        return hidden_states.view(*output_shape), presents\n",
    "\n",
    "class GPT2LMHead(nn.Module):\n",
    "    def __init__(self, model_embeddings_weights, config):\n",
    "        super(GPT2LMHead, self).__init__()\n",
    "        self.n_embd = config.n_embd\n",
    "        self.set_embeddings_weights(model_embeddings_weights)\n",
    "\n",
    "    def set_embeddings_weights(self, model_embeddings_weights):\n",
    "        embed_shape = model_embeddings_weights.shape\n",
    "        self.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\n",
    "        self.decoder.weight = model_embeddings_weights  # Tied weights\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        # Truncated Language modeling logits (we remove the last token)\n",
    "        # h_trunc = h[:, :-1].contiguous().view(-1, self.n_embd)\n",
    "        lm_logits = self.decoder(hidden_state)\n",
    "        return lm_logits\n",
    "\n",
    "class GPT2LMHeadModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(GPT2LMHeadModel, self).__init__()\n",
    "        self.transformer = GPT2Model(config)\n",
    "        self.lm_head = GPT2LMHead(self.transformer.wte.weight, config)\n",
    "\n",
    "    def set_tied(self):\n",
    "        \"\"\" Make sure we are sharing the embeddings\n",
    "        \"\"\"\n",
    "        self.lm_head.set_embeddings_weights(self.transformer.wte.weight)\n",
    "\n",
    "    def forward(self, input_ids, position_ids=None, token_type_ids=None, lm_labels=None, past=None):\n",
    "        hidden_states, presents = self.transformer(input_ids, position_ids, token_type_ids, past)\n",
    "        lm_logits = self.lm_head(hidden_states)\n",
    "        if lm_labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "            loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), lm_labels.view(-1))\n",
    "            return loss\n",
    "        return lm_logits, presents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([47,  0, 46,  0,  8,  1,  0, 53,  0, 46,  0, 54, 59, 58, 65, 64, 64, 54,\n",
      "         1,  0, 50,  0, 46,  0, 26,  1,  0, 51,  0, 46,  0, 36,  1,  0, 49,  0,\n",
      "        46,  0, 21,  1,  0, 48,  0, 46,  0, 18,  1,  0, 52,  0, 46,  0, 41,  2,\n",
      "         3])\n",
      "process1 is Facility1_4, result is <num>43.99<num>, process4 is Facility4_1, process5 is Facility5_4, process3 is Facility3_2, process2 is Facility2_7, process6 is Facility6_1<end><pad>\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    print(batch[0]) # tensor\n",
    "    print(tokenizer.decode(batch[0].tolist())) # string\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 2\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[1;32m      3\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate(model, train_iterator, criterion)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m      8\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(iterator):\n\u001b[0;32m---> 10\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc\u001b[49m\n\u001b[1;32m     11\u001b[0m     trg \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mtrg\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'src'"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, 1)  \n",
    "    valid_loss = evaluate(model, train_iterator, criterion)\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
